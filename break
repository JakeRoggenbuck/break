#!/usr/bin/env python3
import os
from enum import Enum
from dataclasses import dataclass
import random
import shutil


class TokenType(Enum):
    BREAK = 0
    LITERAL = 1
    NOTHING = 2


def find_file():
    files = os.listdir()
    if "Breakfile" in files:
        return "Breakfile"
    elif "breakfile" in files:
        return "breakfile"
    elif "GNObreakfile" in files:
        return "GNObreakfile"


@dataclass
class Token:
    part: str
    token: TokenType


class Break:
    def __init__(self, filepath):
        self.filepath = filepath
        self.size = os.path.getsize(self.filepath)
        self.breakit()

    def breakit(self):
        infile = open(self.filepath, "rb")
        outfile = open(self.filepath + ".$$", "w")

        index = 0
        while index < self.size:
            infile.seek(index)
            char = infile.read(1)
            if random.randint(0, 10) > 7:
                new_char = chr(int.from_bytes(char, byteorder='big') + random.randint(-10, 10))
            else:
                new_char = char.decode("utf-8")

            outfile.write(new_char)

            index += 1

        infile.close()
        outfile.close()

        shutil.move(self.filepath + ".$$", self.filepath)


class Lexer:
    def __init__(self, breakfile_path):
        self.breakfile_path = breakfile_path
        self.tokens = []
        self.index = 0

        self.lex()

    def lex(self):
        with open(self.breakfile_path, 'r') as breakfile:
            for part in breakfile.read().split():
                token = TokenType.BREAK if part == "break" else TokenType.LITERAL
                self.tokens.append(Token(part, token))

    def next_token(self):
        if not len(self.tokens) < self.index + 1:
            _next = self.tokens[self.index]
            self.index += 1
            return _next

    def peak(self):
        if not len(self.tokens) < self.index + 1:
            return self.tokens[self.index]
        else:
            return Token("", TokenType.NOTHING)


def parser(breakfile_path):
    lexer = Lexer(breakfile_path)
    while (tok := lexer.next_token()) != None:
        if tok.token == TokenType.BREAK:
            if lexer.peak().token == TokenType.BREAK:
                raise SyntaxError("You can't break what is already broken")

            elif lexer.peak().token == TokenType.LITERAL:
                Break(lexer.peak().part)


if __name__ == "__main__":
    # By changing this value to true, you are risking permanent damage to files
    # Break does in fact break files without asking questions
    BREAK = False  # Will not break

    if BREAK:
        if (filename := find_file()) != None:
            parser(filename)
    else:
        print("can't break")
