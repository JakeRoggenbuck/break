#!/usr/bin/env python3
import os
import sys
from enum import Enum
from dataclasses import dataclass
import random
import shutil


class TokenType(Enum):
    BREAK = 0
    LITERAL = 1
    NOTHING = 2


def find_file():
    files = os.listdir()
    if "Breakfile" in files:
        return "Breakfile"
    elif "breakfile" in files:
        return "breakfile"
    elif "GNObreakfile" in files:
        return "GNObreakfile"


@dataclass
class Token:
    part: str
    token: TokenType


class Break:
    def __init__(self, filepath, should_break):
        self.should_break = should_break
        self.filepath = filepath
        self.size = os.path.getsize(self.filepath)

        if self.should_break:
            self.breakit()

    def breakit(self):
        infile = open(self.filepath, "rb")
        outfile = open(self.filepath + ".$$", "w")

        index = 0
        while index < self.size:
            infile.seek(index)
            char = infile.read(1)
            if random.randint(0, 10) > 7:
                new_char = chr(int.from_bytes(char, byteorder='big') + random.randint(-10, 10))
            else:
                new_char = char.decode("utf-8")

            outfile.write(new_char)

            index += 1

        infile.close()
        outfile.close()

        shutil.move(self.filepath + ".$$", self.filepath)

        print(f"Broke {self.filepath}")


class Lexer:
    def __init__(self, breakfile_path):
        self.breakfile_path = breakfile_path
        self.tokens = []
        self.index = 0

        self.lex()

    def lex(self):
        with open(self.breakfile_path, 'r') as breakfile:
            for part in breakfile.read().split():
                token = TokenType.BREAK if part == "break" else TokenType.LITERAL
                self.tokens.append(Token(part, token))

    def next_token(self):
        if not len(self.tokens) < self.index + 1:
            _next = self.tokens[self.index]
            self.index += 1
            return _next

    def peak(self):
        if not len(self.tokens) < self.index + 1:
            return self.tokens[self.index]
        else:
            return Token("", TokenType.NOTHING)


def parser(breakfile_path, should_break):
    lexer = Lexer(breakfile_path)
    while (tok := lexer.next_token()) != None:
        if tok.token == TokenType.BREAK:
            if lexer.peak().token == TokenType.BREAK:
                raise SyntaxError("You can't break what is already broken")

            elif lexer.peak().token == TokenType.LITERAL:
                Break(lexer.peak().part, should_break)
                if not should_break:
                    print(f"Would have broken {lexer.peak().part}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "-w":
            should_break = True
    else:
        should_break = False
        print("Not breaking, use -w to really break, be careful!")

    if (filename := find_file()) != None:
        parser(filename, should_break)
        print(f"Using breakfile: {filename}")
    else:
        print("can't find breakfile")
